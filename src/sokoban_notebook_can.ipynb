{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sokoban RL Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\canid\\OneDrive\\Masaüstü\\Python\\CS_175\\sokobanRL\\sokobanRL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\canid\\OneDrive\\Masaüstü\\Python\\CS_175\\sokobanRL\\.venv\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is A45C-F748\n",
      "\n",
      " Directory of c:\\Users\\canid\\OneDrive\\Masa�st�\\Python\\CS_175\\sokobanRL\\sokobanRL\n",
      "\n",
      "12/05/2025  02:57 PM    <DIR>          .\n",
      "12/05/2025  02:15 PM    <DIR>          ..\n",
      "12/03/2025  07:28 PM               952 check_import_by_can.py\n",
      "12/05/2025  11:11 PM    <DIR>          checkpoints\n",
      "12/05/2025  11:43 PM    <DIR>          logs\n",
      "12/03/2025  06:25 PM                 8 README.md\n",
      "12/05/2025  02:58 PM                86 requirements.txt\n",
      "12/06/2025  11:07 AM    <DIR>          src\n",
      "12/05/2025  02:08 PM    <DIR>          test\n",
      "               3 File(s)          1,046 bytes\n",
      "               6 Dir(s)  57,802,874,880 bytes free\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.7)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.2.2)\n",
      "Requirement already satisfied: gym-sokoban in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.0.6)\n",
      "Requirement already satisfied: pygame in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (2.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from gymnasium->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from gymnasium->-r requirements.txt (line 5)) (0.0.4)\n",
      "Requirement already satisfied: gym>=0.2.3 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from gym-sokoban->-r requirements.txt (line 6)) (0.26.2)\n",
      "Requirement already satisfied: tqdm>=4.32.1 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from gym-sokoban->-r requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from gym-sokoban->-r requirements.txt (line 6)) (2.37.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from gym-sokoban->-r requirements.txt (line 6)) (2.32.5)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from gym>=0.2.3->gym-sokoban->-r requirements.txt (line 6)) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from requests>=2.22.0->gym-sokoban->-r requirements.txt (line 6)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from requests>=2.22.0->gym-sokoban->-r requirements.txt (line 6)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from requests>=2.22.0->gym-sokoban->-r requirements.txt (line 6)) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from requests>=2.22.0->gym-sokoban->-r requirements.txt (line 6)) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from tqdm>=4.32.1->gym-sokoban->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\canid\\onedrive\\masaüstü\\python\\cs_175\\sokobanrl\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%ls\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import gym\nimport gym_sokoban\nimport pygame\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom collections import deque\nimport matplotlib.pyplot as plt\nimport os\n\n# NumPy 2.x compatibility patch\nif not hasattr(np, 'bool8'):\n    np.bool8 = np.bool_\nprint(f\"NumPy version: {np.__version__}\")\nprint(\"Compatibility patch applied ✓\")\n\n# Check if GPU is available\ndevice = torch.device(\"cpu\")\nprint(f\"Using device: {device}\")\n\n\n# Reward Shaping Wrapper - STRONGER BONUSES for harder puzzles\nclass SokobanRewardShaper(gym.Wrapper):\n    \"\"\"\n    Reward shaping wrapper using internal room_state for accurate tracking.\n    STRONGER bonuses for harder Boxoban puzzles:\n    - Reward for moving boxes closer to targets: +0.5 per unit (increased from 0.3)\n    - Reward for placing box on target: +2.0 (increased from 1.0)\n    - Penalty for moving boxes away from targets: -0.2 per unit\n    \"\"\"\n    def __init__(self, env):\n        super().__init__(env)\n        self.previous_min_distance = None\n        self.boxes_on_target = 0\n\n    def reset(self, **kwargs):\n        obs = self.env.reset(**kwargs)\n        self.previous_min_distance = self._compute_min_box_target_distance()\n        self.boxes_on_target = self._count_boxes_on_target()\n        return obs\n\n    def _compute_min_box_target_distance(self):\n        \"\"\"Compute sum of minimum distances from each box to nearest target\"\"\"\n        room = self.env.unwrapped.room_state\n\n        # Find box positions (tile value 3 = box on target, 4 = box off target)\n        boxes = np.argwhere((room == 3) | (room == 4))\n\n        # Find target positions (tile value 2 = empty target, 3 = box on target)\n        targets = np.argwhere((room == 2) | (room == 3))\n\n        if len(boxes) == 0 or len(targets) == 0:\n            return 0\n\n        # Calculate sum of minimum Manhattan distances\n        total_min_dist = 0\n        for box in boxes:\n            # Manhattan distance to each target\n            distances = np.abs(targets - box).sum(axis=1)\n            min_dist = distances.min()\n            total_min_dist += min_dist\n\n        return total_min_dist\n\n    def _count_boxes_on_target(self):\n        \"\"\"Count boxes on target positions (tile value 3)\"\"\"\n        room = self.env.unwrapped.room_state\n        return np.sum(room == 3)\n\n    def step(self, action):\n        obs, reward, done, info = self.env.step(action)\n\n        # Start with base reward\n        shaped_reward = reward\n\n        # STRONGER reward for moving boxes closer to targets\n        current_min_distance = self._compute_min_box_target_distance()\n        if self.previous_min_distance is not None:\n            distance_change = self.previous_min_distance - current_min_distance\n            if distance_change > 0:  # Moved closer\n                shaped_reward += 0.5 * distance_change  # Increased from 0.3\n            elif distance_change < 0:  # Moved away\n                shaped_reward += 0.2 * distance_change  # Penalty\n\n        self.previous_min_distance = current_min_distance\n\n        # STRONGER reward for placing box on target\n        current_boxes_on_target = self._count_boxes_on_target()\n        if current_boxes_on_target > self.boxes_on_target:\n            shaped_reward += 2.0 * (current_boxes_on_target - self.boxes_on_target)  # Increased from 1.0\n\n        self.boxes_on_target = current_boxes_on_target\n\n        return obs, shaped_reward, done, info"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor-Critic Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        # Convolutional layers with Layer Normalization for stability\n",
    "        self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.ln1 = nn.LayerNorm([32, input_shape[1]//2, input_shape[2]//2])\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.ln2 = nn.LayerNorm([64, input_shape[1]//4, input_shape[2]//4])\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.ln3 = nn.LayerNorm([64, input_shape[1]//8, input_shape[2]//8])\n",
    "        \n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        \n",
    "        # Actor head (policy) with smaller hidden layer\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 128),  # Reduced from 256\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "        \n",
    "        # Critic head (value function) with smaller hidden layer\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 128),  # Reduced from 256\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # Orthogonal initialization for better gradient flow\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using orthogonal initialization\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.orthogonal_(m.weight, gain=np.sqrt(2))\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight, gain=np.sqrt(2))\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self._forward_conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "    \n",
    "    def _forward_conv(self, x):\n",
    "        \"\"\"Forward pass through convolutional layers\"\"\"\n",
    "        x = torch.relu(self.ln1(self.conv1(x)))\n",
    "        x = torch.relu(self.ln2(self.conv2(x)))\n",
    "        x = torch.relu(self.ln3(self.conv3(x)))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_out = self._forward_conv(x).view(x.size()[0], -1)\n",
    "        return self.actor(conv_out), self.critic(conv_out)\n",
    "    \n",
    "    def get_action_probs(self, x):\n",
    "        logits, _ = self.forward(x)\n",
    "        return torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    def get_value(self, x):\n",
    "        _, value = self.forward(x)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class PPOAgent:\n    def __init__(self, env, lr=3e-4, gamma=0.99, eps_clip=0.2, K_epochs=4, gae_lambda=0.95, \n                 entropy_coef=0.05, value_clip=0.2, warmup_steps=10, advantage_clip=10.0):\n        self.env = env\n        self.gamma = gamma\n        self.eps_clip = eps_clip\n        self.K_epochs = K_epochs\n        self.gae_lambda = gae_lambda\n        self.entropy_coef = entropy_coef\n        self.value_clip = value_clip\n        self.advantage_clip = advantage_clip\n        \n        # Learning rate warmup\n        self.base_lr = lr\n        self.warmup_steps = warmup_steps\n        self.current_update = 0\n        \n        # Get observation shape\n        obs = env.reset()\n        if len(obs.shape) == 3:\n            obs = np.transpose(obs, (2, 0, 1))\n        \n        self.input_shape = obs.shape\n        self.n_actions = env.action_space.n\n        \n        self.device = torch.device(\"cpu\")\n        self.policy = ActorCritic(self.input_shape, self.n_actions).to(self.device)\n        self.optimizer = optim.Adam(self.policy.parameters(), lr=lr)\n        \n        self.policy_old = ActorCritic(self.input_shape, self.n_actions).to(self.device)\n        self.policy_old.load_state_dict(self.policy.state_dict())\n        \n        self.MseLoss = nn.MSELoss()\n    \n    def _get_current_lr(self):\n        \"\"\"Get learning rate with warmup schedule\"\"\"\n        if self.current_update < self.warmup_steps:\n            # Linear warmup from 0 to base_lr\n            return self.base_lr * (self.current_update + 1) / self.warmup_steps\n        else:\n            return self.base_lr\n    \n    def select_action(self, state):\n        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n        with torch.no_grad():\n            action_probs = self.policy_old.get_action_probs(state)\n        \n        dist = torch.distributions.Categorical(action_probs)\n        action = dist.sample()\n        action_logprob = dist.log_prob(action)\n        \n        return action.item(), action_logprob.item()\n    \n    def compute_gae(self, rewards, values, dones):\n        advantages = []\n        gae = 0\n        \n        for t in reversed(range(len(rewards))):\n            if t == len(rewards) - 1:\n                next_value = 0\n            else:\n                next_value = values[t + 1]\n            \n            delta = rewards[t] + self.gamma * next_value * (1 - dones[t]) - values[t]\n            gae = delta + self.gamma * self.gae_lambda * (1 - dones[t]) * gae\n            advantages.insert(0, gae)\n        \n        return advantages\n    \n    def update(self, memory):\n        self.current_update += 1\n        current_lr = self._get_current_lr()\n        \n        # Update learning rate\n        for param_group in self.optimizer.param_groups:\n            param_group['lr'] = current_lr\n        \n        states = torch.FloatTensor(np.array(memory['states'])).to(self.device)\n        actions = torch.LongTensor(memory['actions']).to(self.device)\n        old_logprobs = torch.FloatTensor(memory['logprobs']).to(self.device)\n        \n        rewards = memory['rewards']\n        dones = memory['dones']\n        \n        # Compute values and advantages\n        with torch.no_grad():\n            old_values = self.policy_old.get_value(states).squeeze().cpu().numpy()\n        \n        advantages = self.compute_gae(rewards, old_values, dones)\n        advantages_tensor = torch.FloatTensor(advantages).to(self.device)\n        \n        # Store raw advantage statistics before clipping/normalization\n        raw_adv_mean = advantages_tensor.mean().item()\n        raw_adv_std = advantages_tensor.std().item()\n        raw_adv_max = advantages_tensor.max().item()\n        raw_adv_min = advantages_tensor.min().item()\n        \n        # CLIP advantages to prevent extreme values\n        advantages_tensor = torch.clamp(advantages_tensor, -self.advantage_clip, self.advantage_clip)\n        \n        # Normalize advantages\n        advantages_tensor = (advantages_tensor - advantages_tensor.mean()) / (advantages_tensor.std() + 1e-8)\n        \n        returns = advantages_tensor + torch.FloatTensor(old_values).to(self.device)\n        old_values_tensor = torch.FloatTensor(old_values).to(self.device)\n        \n        # Optimize policy for K epochs\n        total_grad_norm = 0.0\n        for _ in range(self.K_epochs):\n            logits, state_values = self.policy(states)\n            dist = torch.distributions.Categorical(logits=logits)\n            action_logprobs = dist.log_prob(actions)\n            dist_entropy = dist.entropy()\n            \n            ratios = torch.exp(action_logprobs - old_logprobs)\n            \n            surr1 = ratios * advantages_tensor\n            surr2 = torch.clamp(ratios, 1 - self.eps_clip, 1 + self.eps_clip) * advantages_tensor\n            \n            actor_loss = -torch.min(surr1, surr2).mean()\n            \n            # Value function loss with clipping\n            state_values_squeeze = state_values.squeeze()\n            value_pred_clipped = old_values_tensor + torch.clamp(\n                state_values_squeeze - old_values_tensor,\n                -self.value_clip,\n                self.value_clip\n            )\n            value_loss1 = self.MseLoss(state_values_squeeze, returns)\n            value_loss2 = self.MseLoss(value_pred_clipped, returns)\n            critic_loss = torch.max(value_loss1, value_loss2)\n            \n            entropy_loss = -self.entropy_coef * dist_entropy.mean()\n            \n            loss = actor_loss + 0.5 * critic_loss + entropy_loss\n            \n            self.optimizer.zero_grad()\n            loss.backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(self.policy.parameters(), 0.5)\n            total_grad_norm += grad_norm.item()\n            self.optimizer.step()\n        \n        avg_grad_norm = total_grad_norm / self.K_epochs\n        \n        # Calculate policy ratio statistics\n        with torch.no_grad():\n            final_logits, _ = self.policy(states)\n            final_dist = torch.distributions.Categorical(logits=final_logits)\n            final_logprobs = final_dist.log_prob(actions)\n            final_ratios = torch.exp(final_logprobs - old_logprobs)\n            \n            ratio_mean = final_ratios.mean().item()\n            ratio_std = final_ratios.std().item()\n            ratio_max = final_ratios.max().item()\n            ratio_min = final_ratios.min().item()\n        \n        self.policy_old.load_state_dict(self.policy.state_dict())\n        \n        # Return comprehensive metrics\n        metrics = {\n            'actor_loss': actor_loss.item(),\n            'critic_loss': critic_loss.item(),\n            'entropy': -entropy_loss.item() / self.entropy_coef,\n            'grad_norm': avg_grad_norm,\n            'advantage_mean': raw_adv_mean,\n            'advantage_std': raw_adv_std,\n            'advantage_max': raw_adv_max,\n            'advantage_min': raw_adv_min,\n            'ratio_mean': ratio_mean,\n            'ratio_std': ratio_std,\n            'ratio_max': ratio_max,\n            'ratio_min': ratio_min,\n            'value_mean': np.mean(old_values),\n            'value_std': np.std(old_values),\n            'learning_rate': current_lr,\n        }\n        \n        return metrics\n    \n    def save(self, path):\n        torch.save(self.policy.state_dict(), path)\n    \n    def load(self, path):\n        self.policy.load_state_dict(torch.load(path))\n        self.policy_old.load_state_dict(torch.load(path))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env_name='Sokoban-v0', max_episodes=10000, max_timesteps=300, update_timestep=2048, save_freq=100):\n",
    "    import datetime\n",
    "    \n",
    "    # Enable reward shaping for sparse reward exploration\n",
    "    env = gym.make(env_name)\n",
    "    env = SokobanRewardShaper(env)  # Enable reward shaping\n",
    "    \n",
    "    agent = PPOAgent(env)\n",
    "    \n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    \n",
    "    # Create log file with timestamp\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file = f'logs/training_log_{timestamp}.txt'\n",
    "    \n",
    "    # Write header to log file\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(\"=\" * 100 + \"\\n\")\n",
    "        f.write(f\"SOKOBAN PPO TRAINING LOG (WITH REWARD SHAPING) - Started at {datetime.datetime.now()}\\n\")\n",
    "        f.write(\"=\" * 100 + \"\\n\")\n",
    "        f.write(f\"Environment: {env_name} (WITH REWARD SHAPING)\\n\")\n",
    "        f.write(f\"Max Episodes: {max_episodes}\\n\")\n",
    "        f.write(f\"Max Timesteps per Episode: {max_timesteps}\\n\")\n",
    "        f.write(f\"Update Timestep: {update_timestep}\\n\")\n",
    "        f.write(f\"Save Frequency: {save_freq}\\n\")\n",
    "        f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "        f.write(\"HYPERPARAMETER IMPROVEMENTS + REWARD SHAPING:\\n\")\n",
    "        f.write(\"1. REWARD SHAPING ENABLED: Intermediate rewards for box movements\\n\")\n",
    "        f.write(\"   - +0.3 for each unit a box moves closer to targets\\n\")\n",
    "        f.write(\"   - +1.0 for placing a box on a target\\n\")\n",
    "        f.write(\"   - -0.2 for moving a box away from targets\\n\")\n",
    "        f.write(\"2. Layer Normalization: Stabilizes network activations\\n\")\n",
    "        f.write(\"3. Orthogonal Initialization: Better gradient flow\\n\")\n",
    "        f.write(\"4. Value Function Clipping: Prevents critic divergence\\n\")\n",
    "        f.write(\"5. Learning Rate Warmup: Gradual increase (10 updates)\\n\")\n",
    "        f.write(\"6. Advantage Clipping: Prevents extreme advantage values\\n\")\n",
    "        f.write(\"7. IMPROVED Hyperparameters:\\n\")\n",
    "        f.write(\"   - lr=3e-4 (standard PPO learning rate)\\n\")\n",
    "        f.write(\"   - entropy_coef=0.02 (exploration)\\n\")\n",
    "        f.write(\"   - grad_clip=0.5 (stable gradients)\\n\")\n",
    "        f.write(\"   - K_epochs=4\\n\")\n",
    "        f.write(\"   - warmup_steps=10\\n\")\n",
    "        f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "        f.write(\"METRICS EXPLANATION:\\n\")\n",
    "        f.write(\"- Episode: Episode number\\n\")\n",
    "        f.write(\"- Reward: Total reward for this episode (WITH SHAPING BONUSES)\\n\")\n",
    "        f.write(\"- Running Reward: Exponential moving average of rewards\\n\")\n",
    "        f.write(\"- Steps: Number of steps taken in this episode\\n\")\n",
    "        f.write(\"- Timestep: Total timesteps so far\\n\")\n",
    "        f.write(\"- Actor Loss: Policy improvement metric\\n\")\n",
    "        f.write(\"- Critic Loss: Value estimation error\\n\")\n",
    "        f.write(\"- Entropy: Action randomness (target: 0.5-2.0)\\n\")\n",
    "        f.write(\"- Grad Norm: Gradient magnitude\\n\")\n",
    "        f.write(\"- Learning Rate: Current LR with warmup\\n\")\n",
    "        f.write(\"- Ratio Mean: Policy change (should stay near 1.0)\\n\")\n",
    "        f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "        f.write(\"EXPECTED OUTCOMES:\\n\")\n",
    "        f.write(\"- Episodes 1-50: Agent discovers box pushing rewards\\n\")\n",
    "        f.write(\"- Episodes 50-150: Agent learns to push boxes toward targets\\n\")\n",
    "        f.write(\"- Episodes 150-300: First successful box placements\\n\")\n",
    "        f.write(\"- Episodes 300-500: Consistent success rate 20-40%\\n\")\n",
    "        f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "    \n",
    "    print(f\"Logging to: {log_file}\\n\")\n",
    "    print(\"REWARD SHAPING ENABLED:\")\n",
    "    print(\"  - +0.3 per unit boxes move closer to targets\")\n",
    "    print(\"  - +1.0 for placing box on target\")\n",
    "    print(\"  - -0.2 per unit boxes move away from targets\")\n",
    "    print(\"\\nIMPROVED HYPERPARAMETERS ACTIVE:\")\n",
    "    print(\"  - Layer normalization + Orthogonal init\")\n",
    "    print(\"  - Value function clipping + Advantage clipping (±10)\")\n",
    "    print(\"  - Learning rate warmup (10 updates)\")\n",
    "    print(\"  - lr=3e-4, entropy=0.02, grad_clip=0.5, K_epochs=4\\n\")\n",
    "    \n",
    "    episode_rewards = []\n",
    "    episode_steps = []\n",
    "    running_reward = 0\n",
    "    timestep = 0\n",
    "    \n",
    "    # Track latest update metrics\n",
    "    latest_metrics = None\n",
    "    \n",
    "    memory = {\n",
    "        'states': [],\n",
    "        'actions': [],\n",
    "        'logprobs': [],\n",
    "        'rewards': [],\n",
    "        'dones': []\n",
    "    }\n",
    "    \n",
    "    for episode in range(1, max_episodes + 1):\n",
    "        state = env.reset()\n",
    "        if len(state.shape) == 3:\n",
    "            state = np.transpose(state, (2, 0, 1))\n",
    "        \n",
    "        episode_reward = 0\n",
    "        \n",
    "        for t in range(max_timesteps):\n",
    "            timestep += 1\n",
    "            \n",
    "            action, action_logprob = agent.select_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if len(next_state.shape) == 3:\n",
    "                next_state = np.transpose(next_state, (2, 0, 1))\n",
    "            \n",
    "            memory['states'].append(state)\n",
    "            memory['actions'].append(action)\n",
    "            memory['logprobs'].append(action_logprob)\n",
    "            memory['rewards'].append(reward)\n",
    "            memory['dones'].append(done)\n",
    "            \n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            \n",
    "            if timestep % update_timestep == 0:\n",
    "                latest_metrics = agent.update(memory)\n",
    "                memory = {\n",
    "                    'states': [],\n",
    "                    'actions': [],\n",
    "                    'logprobs': [],\n",
    "                    'rewards': [],\n",
    "                    'dones': []\n",
    "                }\n",
    "                print(f\"[UPDATE {agent.current_update}] Timestep {timestep} - \"\n",
    "                      f\"LR: {latest_metrics['learning_rate']:.2e}, \"\n",
    "                      f\"Actor: {latest_metrics['actor_loss']:.4f}, \"\n",
    "                      f\"Critic: {latest_metrics['critic_loss']:.4f}, \"\n",
    "                      f\"Entropy: {latest_metrics['entropy']:.4f}, \"\n",
    "                      f\"GradNorm: {latest_metrics['grad_norm']:.4f}\")\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_steps.append(t + 1)\n",
    "        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
    "        \n",
    "        # Console output\n",
    "        print(f\"Episode {episode:5d} | Reward: {episode_reward:7.2f} | \"\n",
    "              f\"Running: {running_reward:7.2f} | Steps: {t+1:3d}\")\n",
    "        \n",
    "        # Write to log file after EVERY episode\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f\"\\n{'='*100}\\n\")\n",
    "            f.write(f\"EPISODE {episode} (Timestep: {timestep})\\n\")\n",
    "            f.write(f\"{'='*100}\\n\")\n",
    "            f.write(f\"  Reward:          {episode_reward:10.4f}\\n\")\n",
    "            f.write(f\"  Running Reward:  {running_reward:10.4f}\\n\")\n",
    "            f.write(f\"  Steps:           {t+1:10d}\\n\")\n",
    "            f.write(f\"  Total Timestep:  {timestep:10d}\\n\")\n",
    "            \n",
    "            # Add update metrics if available\n",
    "            if latest_metrics is not None:\n",
    "                f.write(f\"\\n  --- Latest Update Metrics (Update #{agent.current_update}) ---\\n\")\n",
    "                f.write(f\"  Learning Rate:   {latest_metrics['learning_rate']:10.8f}  (with warmup)\\n\")\n",
    "                f.write(f\"  Actor Loss:      {latest_metrics['actor_loss']:10.6f}\\n\")\n",
    "                f.write(f\"  Critic Loss:     {latest_metrics['critic_loss']:10.6f}\\n\")\n",
    "                f.write(f\"  Entropy:         {latest_metrics['entropy']:10.6f}\\n\")\n",
    "                f.write(f\"  Grad Norm:       {latest_metrics['grad_norm']:10.6f}\\n\")\n",
    "                f.write(f\"  \\n\")\n",
    "                f.write(f\"  Advantage Mean:  {latest_metrics['advantage_mean']:10.6f}\\n\")\n",
    "                f.write(f\"  Advantage Std:   {latest_metrics['advantage_std']:10.6f}\\n\")\n",
    "                f.write(f\"  Advantage Max:   {latest_metrics['advantage_max']:10.6f}\\n\")\n",
    "                f.write(f\"  Advantage Min:   {latest_metrics['advantage_min']:10.6f}\\n\")\n",
    "                f.write(f\"  \\n\")\n",
    "                f.write(f\"  Ratio Mean:      {latest_metrics['ratio_mean']:10.6f}\\n\")\n",
    "                f.write(f\"  Ratio Std:       {latest_metrics['ratio_std']:10.6f}\\n\")\n",
    "                f.write(f\"  Ratio Max:       {latest_metrics['ratio_max']:10.6f}\\n\")\n",
    "                f.write(f\"  Ratio Min:       {latest_metrics['ratio_min']:10.6f}\\n\")\n",
    "                f.write(f\"  \\n\")\n",
    "                f.write(f\"  Value Mean:      {latest_metrics['value_mean']:10.6f}\\n\")\n",
    "                f.write(f\"  Value Std:       {latest_metrics['value_std']:10.6f}\\n\")\n",
    "        \n",
    "        # Save checkpoints\n",
    "        if episode % save_freq == 0:\n",
    "            agent.save(f'checkpoints/ppo_sokoban_ep{episode}.pth')\n",
    "            print(f\"[CHECKPOINT] Model saved at episode {episode}\")\n",
    "            \n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f\"\\n  >>> CHECKPOINT SAVED: checkpoints/ppo_sokoban_ep{episode}.pth\\n\")\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    # Final summary\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"\\n\\n{'='*100}\\n\")\n",
    "        f.write(f\"TRAINING COMPLETED - {datetime.datetime.now()}\\n\")\n",
    "        f.write(f\"{'='*100}\\n\")\n",
    "        f.write(f\"Total Episodes:       {max_episodes}\\n\")\n",
    "        f.write(f\"Total Timesteps:      {timestep}\\n\")\n",
    "        f.write(f\"Final Running Reward: {running_reward:.4f}\\n\")\n",
    "        f.write(f\"Best Episode Reward:  {max(episode_rewards):.4f} (Episode {episode_rewards.index(max(episode_rewards)) + 1})\\n\")\n",
    "        f.write(f\"Worst Episode Reward: {min(episode_rewards):.4f} (Episode {episode_rewards.index(min(episode_rewards)) + 1})\\n\")\n",
    "        f.write(f\"Average Reward:       {np.mean(episode_rewards):.4f}\\n\")\n",
    "        f.write(f\"Average Steps:        {np.mean(episode_steps):.2f}\\n\")\n",
    "        f.write(f\"{'='*100}\\n\")\n",
    "    \n",
    "    print(f\"\\nTraining complete! Log saved to: {log_file}\")\n",
    "    \n",
    "    return episode_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "Run the cell below to start training. You can adjust the parameters:\n",
    "- `max_episodes`: Total number of episodes to train\n",
    "- `max_timesteps`: Maximum steps per episode\n",
    "- `update_timestep`: How often to update the policy\n",
    "- `save_freq`: How often to save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train on Sokoban-small-v0 (easier, smaller grid)\n# Then gradually move to harder environments\nepisode_rewards = train(\n    env_name='Sokoban-small-v0',\n    max_episodes=10000,\n    max_timesteps=150,  # Shorter episodes for smaller puzzles\n    update_timestep=2048,\n    save_freq=100\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'episode_rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mepisode_rewards\u001b[49m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpisode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'episode_rewards' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training rewards\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(episode_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Episode Rewards')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Plot moving average\n",
    "window_size = 100\n",
    "if len(episode_rewards) >= window_size:\n",
    "    moving_avg = np.convolve(episode_rewards, np.ones(window_size)/window_size, mode='valid')\n",
    "    plt.plot(moving_avg)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Reward')\n",
    "    plt.title(f'Moving Average (window={window_size})')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(checkpoint_path, env_name='Boxoban-Val-v1', num_episodes=5, render=False):\n",
    "    \"\"\"\n",
    "    Test a trained agent without reward shaping.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the checkpoint file\n",
    "        env_name: Environment to test on (default: Boxoban-Val-v1)\n",
    "        num_episodes: Number of episodes to test\n",
    "        render: Whether to render the environment\n",
    "    \n",
    "    Returns:\n",
    "        List of episode rewards (base Sokoban rewards without shaping)\n",
    "    \"\"\"\n",
    "    # Create environment WITHOUT reward shaping for true performance\n",
    "    env = gym.make(env_name)\n",
    "    agent = PPOAgent(env)\n",
    "    agent.load(checkpoint_path)\n",
    "    \n",
    "    total_rewards = []\n",
    "    \n",
    "    print(f\"Testing agent for {num_episodes} episodes on {env_name} (WITHOUT reward shaping)...\\n\")\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        if len(state.shape) == 3:\n",
    "            state = np.transpose(state, (2, 0, 1))\n",
    "        \n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        steps = 0\n",
    "        \n",
    "        while not done and steps < 300:\n",
    "            if render:\n",
    "                env.render()\n",
    "            \n",
    "            action, _ = agent.select_action(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if len(next_state.shape) == 3:\n",
    "                next_state = np.transpose(next_state, (2, 0, 1))\n",
    "            \n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "            steps += 1\n",
    "        \n",
    "        total_rewards.append(episode_reward)\n",
    "        print(f\"Test Episode {episode + 1:2d}: Reward = {episode_reward:7.2f}, Steps = {steps:3d}\")\n",
    "    \n",
    "    env.close()\n",
    "    print(f\"\\nAverage Reward: {np.mean(total_rewards):.2f}\")\n",
    "    return total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: checkpoints/ppo_sokoban_ep2500.pth\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34047772it [00:41, 829889.43it/s]\n",
      "c:\\Users\\canid\\OneDrive\\Masaüstü\\Python\\CS_175\\sokobanRL\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\canid\\OneDrive\\Masaüstü\\Python\\CS_175\\sokobanRL\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\canid\\OneDrive\\Masaüstü\\Python\\CS_175\\sokobanRL\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent for 10 episodes on Boxoban-Val-v1 (WITHOUT reward shaping)...\n",
      "\n",
      "Test Episode  1: Reward =  -20.00, Steps = 200\n",
      "Test Episode  2: Reward =  -19.00, Steps = 200\n",
      "Test Episode  3: Reward =  -20.00, Steps = 200\n",
      "Test Episode  4: Reward =  -20.00, Steps = 200\n",
      "Test Episode  5: Reward =  -20.00, Steps = 200\n",
      "Test Episode  6: Reward =  -20.00, Steps = 200\n",
      "Test Episode  7: Reward =  -20.00, Steps = 200\n",
      "Test Episode  8: Reward =  -19.00, Steps = 200\n",
      "Test Episode  9: Reward =  -20.00, Steps = 200\n",
      "Test Episode 10: Reward =  -18.00, Steps = 200\n",
      "\n",
      "Average Reward: -19.60\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE SUMMARY (on Boxoban validation levels)\n",
      "============================================================\n",
      "Episodes tested: 10\n",
      "Average reward: -19.60\n",
      "Best reward: -18.00\n",
      "Worst reward: -20.00\n",
      "Std deviation: 0.66\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the ep2500 checkpoint on Boxoban validation set\n",
    "checkpoint_path = 'checkpoints/ppo_sokoban_ep2500.pth'\n",
    "\n",
    "print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test on Boxoban validation levels (harder than training levels)\n",
    "test_rewards = test_agent(checkpoint_path, env_name='Boxoban-Val-v1', num_episodes=10, render=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE SUMMARY (on Boxoban validation levels)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Episodes tested: 10\")\n",
    "print(f\"Average reward: {np.mean(test_rewards):.2f}\")\n",
    "print(f\"Best reward: {max(test_rewards):.2f}\")\n",
    "print(f\"Worst reward: {min(test_rewards):.2f}\")\n",
    "print(f\"Std deviation: {np.std(test_rewards):.2f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, 11), test_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Test Episode Rewards on Boxoban-Val (ep2500)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(test_rewards, bins=5, edgecolor='black')\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Reward Distribution (Boxoban)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}